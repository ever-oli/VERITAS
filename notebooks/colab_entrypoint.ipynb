{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6bb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d239043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Git (replace with your details)\n",
    "!git config --global user.email \"your-email@example.com\"\n",
    "!git config --global user.name \"Your Name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set working directory\n",
    "REPO_NAME = \"VERITAS\"\n",
    "GITHUB_USER = \"ever-oli\"  # Replace with your GitHub username\n",
    "WORK_DIR = f\"/content/{REPO_NAME}\"\n",
    "\n",
    "# Clone or pull the repository\n",
    "if not os.path.exists(WORK_DIR):\n",
    "    print(f\"Cloning {REPO_NAME}...\")\n",
    "    !git clone https://github.com/{GITHUB_USER}/{REPO_NAME}.git {WORK_DIR}\n",
    "else:\n",
    "    print(f\"Repository exists. Pulling latest changes...\")\n",
    "    %cd {WORK_DIR}\n",
    "    !git pull\n",
    "\n",
    "# Navigate to repository\n",
    "%cd {WORK_DIR}\n",
    "print(f\"\\nCurrent directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3feace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"Installing requirements...\")\n",
    "!pip install -q -r requirements.txt\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠ No GPU detected. Check runtime settings (Runtime > Change runtime type > GPU)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3bf8f5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ready to Go!\n",
    "\n",
    "Your environment is now set up. Add your training/inference code below or import from the `models/` directory.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "from models.audio_to_ppr import AudioToPPR\n",
    "\n",
    "# Your code here\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
